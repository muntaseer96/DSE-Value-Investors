name: US Stocks Scraper

on:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    # Allow manual trigger from GitHub UI
    inputs:
      sp500_only:
        description: 'Scrape S&P 500 only'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'
      batch_size:
        description: 'Batch size (number of stocks)'
        required: false
        default: '500'

jobs:
  trigger-scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Trigger US Stocks Scrape
        run: |
          echo "Triggering US stocks scrape..."

          # Use input values if manual trigger, otherwise defaults
          # Scheduled runs use sp500_only=false to scrape all stocks by priority
          SP500_ONLY="${{ github.event.inputs.sp500_only || 'false' }}"
          BATCH_SIZE="${{ github.event.inputs.batch_size || '500' }}"

          RESPONSE=$(curl -s -X POST \
            "https://dse-value-investors-production.up.railway.app/us-stocks/trigger-scrape?sp500_only=${SP500_ONLY}&batch_size=${BATCH_SIZE}")

          echo "Response: $RESPONSE"

          # Check if scrape started successfully
          STATUS=$(echo $RESPONSE | jq -r '.status // "error"')
          if [ "$STATUS" = "started" ] || [ "$STATUS" = "already_running" ]; then
            echo "✅ Scrape triggered successfully!"
            echo $RESPONSE | jq .
          else
            echo "❌ Failed to trigger scrape"
            echo $RESPONSE | jq .
            exit 1
          fi

      - name: Wait and Check Progress
        run: |
          echo "Waiting 30 seconds before checking progress..."
          sleep 30

          echo "Progress:"
          curl -s "https://dse-value-investors-production.up.railway.app/us-stocks/scrape-status" | jq .
